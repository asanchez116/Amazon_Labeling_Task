{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import spacy\n",
    "from spacy import displacy\n",
    "from spacy.matcher import Matcher\n",
    "import os\n",
    "import numpy as np\n",
    "import random \n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting en-core-web-lg==3.2.0\n",
      "  Downloading https://github.com/explosion/spacy-models/releases/download/en_core_web_lg-3.2.0/en_core_web_lg-3.2.0-py3-none-any.whl (777.4 MB)\n",
      "Requirement already satisfied: spacy<3.3.0,>=3.2.0 in c:\\users\\asanchez\\appdata\\local\\continuum\\anaconda3\\envs\\pythondata\\lib\\site-packages (from en-core-web-lg==3.2.0) (3.2.0)\n",
      "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<1.9.0,>=1.7.4 in c:\\users\\asanchez\\appdata\\local\\continuum\\anaconda3\\envs\\pythondata\\lib\\site-packages (from spacy<3.3.0,>=3.2.0->en-core-web-lg==3.2.0) (1.8.2)\n",
      "Requirement already satisfied: pathy>=0.3.5 in c:\\users\\asanchez\\appdata\\local\\continuum\\anaconda3\\envs\\pythondata\\lib\\site-packages (from spacy<3.3.0,>=3.2.0->en-core-web-lg==3.2.0) (0.6.0)\n",
      "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.8 in c:\\users\\asanchez\\appdata\\local\\continuum\\anaconda3\\envs\\pythondata\\lib\\site-packages (from spacy<3.3.0,>=3.2.0->en-core-web-lg==3.2.0) (3.0.8)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\asanchez\\appdata\\local\\continuum\\anaconda3\\envs\\pythondata\\lib\\site-packages (from spacy<3.3.0,>=3.2.0->en-core-web-lg==3.2.0) (21.3)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.13.0 in c:\\users\\asanchez\\appdata\\local\\continuum\\anaconda3\\envs\\pythondata\\lib\\site-packages (from spacy<3.3.0,>=3.2.0->en-core-web-lg==3.2.0) (2.26.0)\n",
      "Requirement already satisfied: thinc<8.1.0,>=8.0.12 in c:\\users\\asanchez\\appdata\\local\\continuum\\anaconda3\\envs\\pythondata\\lib\\site-packages (from spacy<3.3.0,>=3.2.0->en-core-web-lg==3.2.0) (8.0.13)\n",
      "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in c:\\users\\asanchez\\appdata\\local\\continuum\\anaconda3\\envs\\pythondata\\lib\\site-packages (from spacy<3.3.0,>=3.2.0->en-core-web-lg==3.2.0) (3.0.5)\n",
      "Requirement already satisfied: numpy>=1.15.0 in c:\\users\\asanchez\\appdata\\local\\continuum\\anaconda3\\envs\\pythondata\\lib\\site-packages (from spacy<3.3.0,>=3.2.0->en-core-web-lg==3.2.0) (1.20.3)\n",
      "Requirement already satisfied: srsly<3.0.0,>=2.4.1 in c:\\users\\asanchez\\appdata\\local\\continuum\\anaconda3\\envs\\pythondata\\lib\\site-packages (from spacy<3.3.0,>=3.2.0->en-core-web-lg==3.2.0) (2.4.1)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\asanchez\\appdata\\local\\continuum\\anaconda3\\envs\\pythondata\\lib\\site-packages (from spacy<3.3.0,>=3.2.0->en-core-web-lg==3.2.0) (2.11.3)\n",
      "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in c:\\users\\asanchez\\appdata\\local\\continuum\\anaconda3\\envs\\pythondata\\lib\\site-packages (from spacy<3.3.0,>=3.2.0->en-core-web-lg==3.2.0) (2.0.5)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in c:\\users\\asanchez\\appdata\\local\\continuum\\anaconda3\\envs\\pythondata\\lib\\site-packages (from spacy<3.3.0,>=3.2.0->en-core-web-lg==3.2.0) (4.62.3)\n",
      "Requirement already satisfied: wasabi<1.1.0,>=0.8.1 in c:\\users\\asanchez\\appdata\\local\\continuum\\anaconda3\\envs\\pythondata\\lib\\site-packages (from spacy<3.3.0,>=3.2.0->en-core-web-lg==3.2.0) (0.8.2)\n",
      "Requirement already satisfied: typer<0.5.0,>=0.3.0 in c:\\users\\asanchez\\appdata\\local\\continuum\\anaconda3\\envs\\pythondata\\lib\\site-packages (from spacy<3.3.0,>=3.2.0->en-core-web-lg==3.2.0) (0.4.0)\n",
      "Requirement already satisfied: blis<0.8.0,>=0.4.0 in c:\\users\\asanchez\\appdata\\local\\continuum\\anaconda3\\envs\\pythondata\\lib\\site-packages (from spacy<3.3.0,>=3.2.0->en-core-web-lg==3.2.0) (0.7.4)\n",
      "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in c:\\users\\asanchez\\appdata\\local\\continuum\\anaconda3\\envs\\pythondata\\lib\\site-packages (from spacy<3.3.0,>=3.2.0->en-core-web-lg==3.2.0) (2.0.6)\n",
      "Requirement already satisfied: setuptools in c:\\users\\asanchez\\appdata\\local\\continuum\\anaconda3\\envs\\pythondata\\lib\\site-packages (from spacy<3.3.0,>=3.2.0->en-core-web-lg==3.2.0) (58.0.4)\n",
      "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in c:\\users\\asanchez\\appdata\\local\\continuum\\anaconda3\\envs\\pythondata\\lib\\site-packages (from spacy<3.3.0,>=3.2.0->en-core-web-lg==3.2.0) (1.0.5)\n",
      "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in c:\\users\\asanchez\\appdata\\local\\continuum\\anaconda3\\envs\\pythondata\\lib\\site-packages (from spacy<3.3.0,>=3.2.0->en-core-web-lg==3.2.0) (3.3.0)\n",
      "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in c:\\users\\asanchez\\appdata\\local\\continuum\\anaconda3\\envs\\pythondata\\lib\\site-packages (from spacy<3.3.0,>=3.2.0->en-core-web-lg==3.2.0) (1.0.1)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in c:\\users\\asanchez\\appdata\\local\\continuum\\anaconda3\\envs\\pythondata\\lib\\site-packages (from packaging>=20.0->spacy<3.3.0,>=3.2.0->en-core-web-lg==3.2.0) (3.0.4)\n",
      "Requirement already satisfied: smart-open<6.0.0,>=5.0.0 in c:\\users\\asanchez\\appdata\\local\\continuum\\anaconda3\\envs\\pythondata\\lib\\site-packages (from pathy>=0.3.5->spacy<3.3.0,>=3.2.0->en-core-web-lg==3.2.0) (5.2.1)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\users\\asanchez\\appdata\\local\\continuum\\anaconda3\\envs\\pythondata\\lib\\site-packages (from pydantic!=1.8,!=1.8.1,<1.9.0,>=1.7.4->spacy<3.3.0,>=3.2.0->en-core-web-lg==3.2.0) (3.10.0.2)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\asanchez\\appdata\\local\\continuum\\anaconda3\\envs\\pythondata\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy<3.3.0,>=3.2.0->en-core-web-lg==3.2.0) (2021.10.8)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\asanchez\\appdata\\local\\continuum\\anaconda3\\envs\\pythondata\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy<3.3.0,>=3.2.0->en-core-web-lg==3.2.0) (3.3)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\asanchez\\appdata\\local\\continuum\\anaconda3\\envs\\pythondata\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy<3.3.0,>=3.2.0->en-core-web-lg==3.2.0) (1.26.7)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in c:\\users\\asanchez\\appdata\\local\\continuum\\anaconda3\\envs\\pythondata\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy<3.3.0,>=3.2.0->en-core-web-lg==3.2.0) (2.0.4)\n",
      "Requirement already satisfied: colorama in c:\\users\\asanchez\\appdata\\local\\continuum\\anaconda3\\envs\\pythondata\\lib\\site-packages (from tqdm<5.0.0,>=4.38.0->spacy<3.3.0,>=3.2.0->en-core-web-lg==3.2.0) (0.4.4)\n",
      "Requirement already satisfied: click<9.0.0,>=7.1.1 in c:\\users\\asanchez\\appdata\\local\\continuum\\anaconda3\\envs\\pythondata\\lib\\site-packages (from typer<0.5.0,>=0.3.0->spacy<3.3.0,>=3.2.0->en-core-web-lg==3.2.0) (8.0.3)\n",
      "Requirement already satisfied: MarkupSafe>=0.23 in c:\\users\\asanchez\\appdata\\local\\continuum\\anaconda3\\envs\\pythondata\\lib\\site-packages (from jinja2->spacy<3.3.0,>=3.2.0->en-core-web-lg==3.2.0) (1.1.1)\n",
      "[+] Download and installation successful\n",
      "You can now load the package via spacy.load('en_core_web_lg')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-12-07 14:59:44.076877: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'cudart64_110.dll'; dlerror: cudart64_110.dll not found\n",
      "2021-12-07 14:59:44.076903: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n",
      "2021-12-07 14:59:44.150562: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'cudart64_110.dll'; dlerror: cudart64_110.dll not found\n",
      "2021-12-07 14:59:44.150581: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n",
      "2021-12-07 14:59:44.224248: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'cudart64_110.dll'; dlerror: cudart64_110.dll not found\n",
      "2021-12-07 14:59:44.224264: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n",
      "2021-12-07 14:59:44.322416: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'cudart64_110.dll'; dlerror: cudart64_110.dll not found\n",
      "2021-12-07 14:59:44.322436: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n"
     ]
    }
   ],
   "source": [
    "!python -m spacy download en_core_web_lg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir('O:/Amazon/2021/AMZ210470 Major Appliances/1_Behavioral Data Analysis/output')\n",
    "data_file = '02_Relevant Sessions_Detail.csv'\n",
    "df = pd.read_csv(data_file, encoding=\"ISO-8859-1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load(\"en_core_web_lg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "titles = [_ for _ in df['keyword_search'].dropna().str.lower()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Rules based keyword matching for labeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "range_pattern1 = [{\"LEMMA\": {\"IN\":[\"range\",\"stove\", \"burner\", \"cooktop\",\"stovetop\"]}, \"POS\": \"NOUN\"},\n",
    "                  {\"LOWER\":{\"IN\":[\"built\",\"top\"]}}, \n",
    "                  {\"LOWER\":{\"NOT_IN\":[\"stuffing\"]}}]\n",
    "\n",
    "refridgerator_pattern = [{'LEMMA':{'IN':['refridgerator', 'fridge', 'freezer']}, \"DEP\":{\"NOT_IN\":[\"attr\"]}}]\n",
    "\n",
    "appliances_pattern = [{\"LEMMA\":{\"IN\":[\"kitchen\"]}, \"LEMMA\":{\"NOT_IN\":[\"small\"]}},\n",
    "                      {'LEMMA':'appliance'},\n",
    "                     {\"POS\":\"NOUN\", \"OP\":\"?\"}]\n",
    "\n",
    "microwave_pattern = [{\"IS_PUNCT\":False, \"OP\":\"*\"},\n",
    "                      {'LEMMA':'microwave', \"DEP\":{\"NOT_IN\":[\"appos\", \"pobj\"]}},\n",
    "                    {\"POS\":\"PROPN\", \"OP\": \"!\", 'LOWER':'oven', \"OP\":\"*\",\"IS_PUNCT\":False}]\n",
    "\n",
    "oven_pattern = [{\"LEMMA\":{\"NOT_IN\":[\"brick\", \"pizza\"]},\"POS\":{\"NOT_IN\":[\"VERB\"]}},\n",
    "                 {\"LEMMA\":\"oven\"}]\n",
    "\n",
    "washer_pattern1 = [{\"LEMMA\":{\"NOT_IN\":[\"window\", \"power\"]}},\n",
    "                  {'LEMMA':{\"IN\":[\"washer\", \"dishwasher\", \"washing\"]}},\n",
    "                 {\"LOWER\":{\"NOT_IN\":[\"pods\",\"detergent\",\"repair\",\"pacs\",\"method\"]}}]\n",
    "                                     \n",
    "dryer_pattern = [{'LEMMA':'dryer'},\n",
    "                 {\"LEMMA\":{\"NOT_IN\":[\"sheets\"]}}]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "matcher = Matcher(nlp.vocab, validate=True)\n",
    "matcher.add(\"RANGE\", [range_pattern1])\n",
    "matcher.add(\"FRIDGE\", [refridgerator_pattern])\n",
    "matcher.add(\"APPLIANCE\", [appliances_pattern])\n",
    "matcher.add(\"MICROWAVE\", [microwave_pattern])\n",
    "matcher.add(\"OVEN\", [oven_pattern])\n",
    "matcher.add(\"WASHER\", [washer_pattern1])\n",
    "matcher.add(\"DRYER\", [dryer_pattern])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mini fridge\n",
      "lg builtin oven'\n",
      "over the oven microwave\n",
      "fridge\n",
      "lg wall oven\n",
      "electric dryers in stock\n",
      "mini fridge\n",
      "microwave\n",
      "smart oven pro\n",
      "top load washer dryer sets\n"
     ]
    }
   ],
   "source": [
    "g = (d for d in nlp.pipe(titles) if len(matcher(d)) > 0)\n",
    "for i in range(10):\n",
    "    print(next(g))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('washer', 'NOUN', 'nsubj', 'washer'),\n",
       " ('and', 'CCONJ', 'cc', 'and'),\n",
       " ('dryer', 'NOUN', 'conj', 'dryer'),\n",
       " ('set', 'NOUN', 'ROOT', 'set')]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_text = nlp(\"washer and dryer set\")\n",
    "[(i.text, i.pos_, i.dep_, i.lemma_ \n",
    "  #, [(i.text, i.label_) for i in test_text.ents]\n",
    " ) for i in nlp(test_text)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "text:  washer and dryer set \n",
      " Matches:  dryer set\n"
     ]
    }
   ],
   "source": [
    "for match_id, start, end in matcher(nlp(test_text)):\n",
    "    print(\"text: \",test_text, \"\\n\", \"Matches: \",test_text[start: end])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prettier way to display\n",
    "from IPython.display import HTML as html_print\n",
    "\n",
    "def style(s, bold=False):\n",
    "    blob = f\"<text>{s}</text>\"\n",
    "    if bold:\n",
    "        blob = f\"<b style='background-color: #fff59d'>{blob}</b>\"\n",
    "    return blob\n",
    "\n",
    "def html_generator(g, n=10):\n",
    "    blob = \"\"\n",
    "    for i in range(n):\n",
    "        doc = next(g)\n",
    "\n",
    "        state = [[t, False] for t in doc]\n",
    "        for idx, start, end in matcher(doc):\n",
    "            for i in range(start, end):\n",
    "                state[i][1] = True\n",
    "        blob += style(' '.join([style(str(t[0]), bold=t[1]) for t in state]) + '<br>') \n",
    "    return blob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<text><text>mini</text> <b style='background-color: #fff59d'><text>fridge</text></b><br></text><text><text>lg</text> <b style='background-color: #fff59d'><text>builtin</text></b> <b style='background-color: #fff59d'><text>oven</text></b> <text>'</text><br></text><text><text>over</text> <b style='background-color: #fff59d'><text>the</text></b> <b style='background-color: #fff59d'><text>oven</text></b> <text>microwave</text><br></text><text><b style='background-color: #fff59d'><text>fridge</text></b><br></text><text><text>lg</text> <b style='background-color: #fff59d'><text>wall</text></b> <b style='background-color: #fff59d'><text>oven</text></b><br></text><text><text>electric</text> <b style='background-color: #fff59d'><text>dryers</text></b> <b style='background-color: #fff59d'><text>in</text></b> <text>stock</text><br></text><text><text>mini</text> <b style='background-color: #fff59d'><text>fridge</text></b><br></text><text><b style='background-color: #fff59d'><text>microwave</text></b><br></text><text><b style='background-color: #fff59d'><text>smart</text></b> <b style='background-color: #fff59d'><text>oven</text></b> <text>pro</text><br></text><text><text>top</text> <b style='background-color: #fff59d'><text>load</text></b> <b style='background-color: #fff59d'><text>washer</text></b> <b style='background-color: #fff59d'><text>dryer</text></b> <b style='background-color: #fff59d'><text>sets</text></b><br></text>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "g = (d for d in nlp.pipe(titles) if matcher(d))\n",
    "html_print(html_generator(g, n=10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Keyword similarity for labeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\asanchez\\AppData\\Local\\Continuum\\anaconda3\\envs\\PythonData\\lib\\site-packages\\gensim\\similarities\\__init__.py:15: UserWarning: The gensim.similarities.levenshtein submodule is disabled, because the optional Levenshtein package <https://pypi.org/project/python-Levenshtein/> is unavailable. Install Levenhstein (e.g. `pip install python-Levenshtein`) to suppress this warning.\n",
      "  warnings.warn(msg)\n"
     ]
    }
   ],
   "source": [
    "from gensim.models import Word2Vec\n",
    "import gensim\n",
    "from gensim.utils import simple_preprocess\n",
    "import os\n",
    "# kernel kept crashing due to duplicate library - temporary fix\n",
    "os.environ['KMP_DUPLICATE_LIB_OK']='True'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['ge', 'jvm', 'rfss', 'over', 'the', 'range', 'microwave', 'oven', 'in', 'white']\n"
     ]
    }
   ],
   "source": [
    "segments = []\n",
    "\n",
    "for segment in titles:\n",
    "    segment = simple_preprocess(segment, deacc = True)\n",
    "    if len(segment) > 5:\n",
    "        segments.append(segment)\n",
    "print(segments[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train on word vectors \n",
    "model = Word2Vec(segments, min_count=5)\n",
    "model.save(\"demo.bin\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test on keyword\n",
    "model = Word2Vec.load(\"demo.bin\")\n",
    "keyword = \"samsung\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = model.wv.similar_by_word(keyword, topn=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('operated', 0.5106416940689087)\n",
      "('glass', 0.4867037534713745)\n",
      "('steam', 0.48629769682884216)\n",
      "('dryer', 0.4719146192073822)\n",
      "('full', 0.4703497886657715)\n",
      "('with', 0.46883806586265564)\n",
      "('washer', 0.4675185978412628)\n",
      "('stainless', 0.4668442904949188)\n",
      "('cu', 0.4636915624141693)\n",
      "('machine', 0.46108725666999817)\n",
      "('electric', 0.45737460255622864)\n",
      "('capacity', 0.45009106397628784)\n",
      "('ft', 0.44807517528533936)\n",
      "('gas', 0.44602328538894653)\n",
      "('fridge', 0.4452834129333496)\n",
      "('steel', 0.4344782829284668)\n",
      "('load', 0.4256725013256073)\n",
      "('efficiency', 0.4254148006439209)\n",
      "('commercial', 0.42449119687080383)\n",
      "('and', 0.4223501682281494)\n"
     ]
    }
   ],
   "source": [
    "for item in res:\n",
    "    print(item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use above to generate search word list along with relevant keywords list from excel  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "search_words = [\"microwave\", \"induction\",\"griddle\",\"broiler\",\"dishwasher\", \n",
    "                \"refridgerator\", \"cooktop\" ,\"dryer\", \"fridge\", \"freezer\", \n",
    "                \"oven\", \"washing\", \"convection\",\"machines\",\"samsung\",\"efficiency\",\"load\",\"commercial\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = []\n",
    "\n",
    "for segment in segments:\n",
    "    for word in search_words:\n",
    "        if word in segment:\n",
    "            match = True\n",
    "    if match == True:\n",
    "        segment = \" \".join(segment)\n",
    "        train_data.append((segment, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('samsung stormwash top control built in dishwasher with autorelease dry', 1)]\n"
     ]
    }
   ],
   "source": [
    "print([train_data[random.randint(0, len(train_data))]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
